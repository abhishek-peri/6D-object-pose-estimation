{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18082,
     "status": "ok",
     "timestamp": 1670438023318,
     "user": {
      "displayName": "Abhishek Peri",
      "userId": "07363149399044203383"
     },
     "user_tz": 480
    },
    "id": "7f0zmLhYaZoR",
    "outputId": "2b34fd05-2ff2-4ad0-98b8-34de0c3f5d4f"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3AXRXlhkastc",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!unzip ./training_data_filtered.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6028,
     "status": "ok",
     "timestamp": 1670438036151,
     "user": {
      "displayName": "Abhishek Peri",
      "userId": "07363149399044203383"
     },
     "user_tz": 480
    },
    "id": "aPTgTSRzbKOW"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm,trange\n",
    "\n",
    "# set device for PyTorch\n",
    "has_gpu = torch.cuda.is_available()\n",
    "has_mps = getattr(torch,'has_mps',False)\n",
    "device = \"mps\" if getattr(torch,'has_mps',False) \\\n",
    "    else \"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# set up the dataset locations\n",
    "training_data_dir = \"training_data_filtered/training_data/v2.2\"\n",
    "split_dir = \"training_data_filtered/training_data/splits/v2\"\n",
    "objects_csv = 'training_data_filtered/training_data/objects_v1.csv'\n",
    "\n",
    "def get_split_files(split_name):\n",
    "    with open(os.path.join(split_dir, f\"{split_name}.txt\"), 'r') as f:\n",
    "        prefix = [os.path.join(training_data_dir, line.strip()) for line in f if line.strip()]\n",
    "        rgb = [p + \"_color_kinect.png\" for p in prefix]\n",
    "        depth = [p + \"_depth_kinect.png\" for p in prefix]\n",
    "        label = [p + \"_label_kinect.png\" for p in prefix]\n",
    "        meta = [p + \"_meta.pkl\" for p in prefix]\n",
    "    return rgb, depth, label, meta\n",
    "\n",
    "rgb_files, depth_files, label_files, meta_files = get_split_files('train')\n",
    "rgb_files_val, depth_files_val, label_files_val, meta_files_val = get_split_files('val')\n",
    "\n",
    "# define the dataset class\n",
    "\n",
    "def read_image(img_path):\n",
    "    '''\n",
    "    inputs:\n",
    "    img_path : the location of the image to be read\n",
    "    outputs:\n",
    "    image converted to torch.tensor\n",
    "    '''\n",
    "    image = np.array(Image.open(img_path))\n",
    "#     print(image)\n",
    "    image = torch.from_numpy(image)\n",
    "    return image\n",
    "\n",
    "class mydataset(Dataset):\n",
    "    # define the init method\n",
    "    def __init__(self, annotations_files, img_files, img_dir, object_files, transform=None, target_transform = None) -> None:\n",
    "        super().__init__()\n",
    "        self.target_labels = annotations_files\n",
    "        self.img_dir = img_dir\n",
    "        self.img_files = img_files\n",
    "        self.objects = pd.read_csv(object_files)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    # define the len method\n",
    "    def __len__(self):\n",
    "        return len(self.target_labels)\n",
    "\n",
    "    # define the getitem() method\n",
    "    def __getitem__(self,idx):\n",
    "        img_path = self.img_files[idx]#os.path.join(self.img_dir, self.img_files[idx])\n",
    "        target_path = self.target_labels[idx]#os.path.join(self.img_dir, self.target_labels[idx])\n",
    "        image = read_image(img_path)/255.0 # divide by 255 or do some normalization using transforms\n",
    "        label = read_image(target_path)\n",
    "        if self.transform:\n",
    "            image  = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n",
    "\n",
    "training_data = mydataset(label_files,rgb_files,training_data_dir,objects_csv)\n",
    "validation_data = mydataset(label_files_val,rgb_files_val,training_data_dir,objects_csv)\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=1, shuffle=True)\n",
    "val_dataloader = DataLoader(validation_data, batch_size=1,shuffle=True)\n",
    "\n",
    "# train_features, train_labels = next(iter(train_dataloader))\n",
    "# val_features, val_labels = next(iter(val_dataloader))\n",
    "\n",
    "# print(train_features.size())\n",
    "# print(train_labels.size())\n",
    "\n",
    "# print(f\"max :{train_labels.max()}\")\n",
    "\n",
    "# print(val_features.size())\n",
    "# print(val_labels.size())\n",
    "\n",
    "# visualize the dataset elements and verify if they are loading correctly\n",
    "\n",
    "# img = train_features[0].squeeze()\n",
    "# label = train_labels[0]\n",
    "# plt.imshow(label)\n",
    "# plt.show()\n",
    "\n",
    "# create a dataloader now or in the train routine\n",
    "\n",
    "# define the network\n",
    "\n",
    "class Segmentation(nn.Module): \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1, padding_mode=\"reflect\"),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            # nn.Conv2d(64, 64, 3, padding=1, padding_mode=\"reflect\"),\n",
    "            # nn.BatchNorm2d(64),\n",
    "            # nn.ReLU(),\n",
    "        )\n",
    "        self.c2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, padding=1, padding_mode=\"reflect\"),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            # nn.Conv2d(128, 128, 3, padding=1, padding_mode=\"reflect\"),\n",
    "            # nn.BatchNorm2d(128),\n",
    "            # nn.ReLU(),\n",
    "        )\n",
    "        self.c3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3, padding=1, padding_mode=\"reflect\"),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            # nn.Conv2d(256, 256, 3, padding=1, padding_mode=\"reflect\"),\n",
    "            # nn.BatchNorm2d(256),\n",
    "            # nn.ReLU(),\n",
    "        )\n",
    "        self.c4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, 3, padding=1, padding_mode=\"reflect\"),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            # nn.Conv2d(512, 512, 3, padding=1, padding_mode=\"reflect\"),\n",
    "            # nn.BatchNorm2d(512),\n",
    "            # nn.ReLU(),\n",
    ")\n",
    "        self.p1 = nn.MaxPool2d(2)\n",
    "        self.p2 = nn.MaxPool2d(2)\n",
    "        self.p3 = nn.MaxPool2d(2)\n",
    "        self.d1 = nn.ConvTranspose2d(128, 64, 2, 2)\n",
    "        self.d2 = nn.ConvTranspose2d(256, 128, 2, 2)\n",
    "        self.d3 = nn.ConvTranspose2d(512, 256, 2, 2)\n",
    "        self.dc1 = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, 3, padding=1, padding_mode=\"reflect\"),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            # nn.Conv2d(64, 64, 3, padding=1, padding_mode=\"reflect\"),\n",
    "            # nn.BatchNorm2d(64),\n",
    "            # nn.ReLU(),\n",
    "            nn.Conv2d(64, 82, 1),\n",
    "#             nn.BatchNorm2d(82),\n",
    "#             nn.ReLU(),\n",
    "        )\n",
    "        self.dc2 = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, 3, padding=1, padding_mode=\"reflect\"),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            # nn.Conv2d(128, 128, 3, padding=1, padding_mode=\"reflect\"),\n",
    "            # nn.BatchNorm2d(128),\n",
    "            # nn.ReLU(),\n",
    ")\n",
    "        self.dc3 = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, 3, padding=1, padding_mode=\"reflect\"),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            # nn.Conv2d(256, 256, 3, padding=1, padding_mode=\"reflect\"),\n",
    "            # nn.BatchNorm2d(256),\n",
    "            # nn.ReLU(),\n",
    ")\n",
    "    def forward(self, x): \n",
    "        x1 = self.c1(x)\n",
    "#         print(x1.size())\n",
    "        x2 = self.c2(self.p1(x1))\n",
    "#         print(x2.size())\n",
    "        x3 = self.c3(self.p2(x2))\n",
    "#         print(x3.size())\n",
    "        x4 = self.c4(self.p3(x3))\n",
    "#         print(x4.size())\n",
    "        y3 = torch.cat([x3, self.d3(x4)], dim=1)\n",
    "#         print(y3.size())\n",
    "        y2 = torch.cat([x2, self.d2(self.dc3(y3))], dim=1)\n",
    "#         print(y2.size())\n",
    "        y1 = torch.cat([x1, self.d1(self.dc2(y2))], dim=1)\n",
    "#         print(y1.size())\n",
    "        output = self.dc1(y1).squeeze(1)\n",
    "#         print(output.size())\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KQ-iUNw4cjEo",
    "outputId": "119327d3-16bb-4e2d-8e5b-c0d22087f8ba"
   },
   "outputs": [],
   "source": [
    "# test inference on random weights\n",
    "\n",
    "device = \"cuda\"\n",
    "# model = UNET_mod(in_channels=3, classes=82)\n",
    "model = Segmentation()\n",
    "model.to(device)\n",
    "# # print(model)\n",
    "# inp = torch.permute(train_features,(0,3,1,2)).to(device)\n",
    "# print(inp.type())\n",
    "# out = model(inp)\n",
    "# print(f\"out: {out.size()}\")\n",
    "\n",
    "# define the optimizer and criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# define the hyper paramteres for now lr, batch_size, num_iterations\n",
    "batch_size = 1\n",
    "epochs = 5\n",
    "print_freq = 10\n",
    "epoch_save = 100\n",
    "batch_loss = []\n",
    "# define the train routine\n",
    "for epoch in trange(epochs):\n",
    "    print_count = 0\n",
    "    print_loss = 0\n",
    "    epoch_step = 0\n",
    "    for data in train_dataloader:\n",
    "        epoch_step += 1\n",
    "        print_count += 1\n",
    "        result = model(torch.permute(data[0],(0,3,1,2)).to(device))\n",
    "        optim.zero_grad()\n",
    "        loss = criterion(result, data[1].type(torch.LongTensor).to(device))\n",
    "        # print(loss.item())\n",
    "        print_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        # print(print_loss)\n",
    "        if(print_count % print_freq == 0): \n",
    "            print(f\"[{epoch+1}/{epochs}][{epoch_step}/{len(train_dataloader)}]\") \n",
    "            print(f\"loss: {print_loss / print_freq}\")\n",
    "            batch_loss.append(print_loss / print_freq)\n",
    "            print_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "a = np.arange(10,19810,10)\n",
    "plt.plot(a,batch_loss)\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SoDW8TABdUrl"
   },
   "outputs": [],
   "source": [
    "torch.save(model, f\"./model_new_plot_{epoch+1}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3817,
     "status": "ok",
     "timestamp": 1670407304694,
     "user": {
      "displayName": "Abhishek Peri",
      "userId": "07363149399044203383"
     },
     "user_tz": 480
    },
    "id": "AVfmcQxfwTVM",
    "outputId": "bfdb40a0-2399-48fb-e531-3cca9c62334c"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "model = torch.load(\"./model_new_5.pth\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "test = next(iter(val_dataloader))\n",
    "print(test[0].size())\n",
    "out_test = model(torch.permute(test[0],(0,3,1,2)).to(device))\n",
    "print(out_test.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 421,
     "status": "ok",
     "timestamp": 1670407314634,
     "user": {
      "displayName": "Abhishek Peri",
      "userId": "07363149399044203383"
     },
     "user_tz": 480
    },
    "id": "GKSj3vTRwuT0",
    "outputId": "17123925-5f40-49f4-812d-f80834327600"
   },
   "outputs": [],
   "source": [
    "test_labels = torch.argmax(out_test,dim=1)\n",
    "print(test_labels.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "executionInfo": {
     "elapsed": 336,
     "status": "ok",
     "timestamp": 1670407317007,
     "user": {
      "displayName": "Abhishek Peri",
      "userId": "07363149399044203383"
     },
     "user_tz": 480
    },
    "id": "-M_-9NyYxxqi",
    "outputId": "d1257950-9e25-48d7-c2d4-cc08219a5401"
   },
   "outputs": [],
   "source": [
    "from matplotlib.cm import get_cmap\n",
    "\n",
    "NUM_OBJECTS = 79\n",
    "cmap = get_cmap('rainbow', NUM_OBJECTS)\n",
    "COLOR_PALETTE = np.array([cmap(i)[:3] for i in range(NUM_OBJECTS + 3)])\n",
    "COLOR_PALETTE = np.array(COLOR_PALETTE * 255, dtype=np.uint8)\n",
    "COLOR_PALETTE[-3] = [119, 135, 150]\n",
    "COLOR_PALETTE[-2] = [176, 194, 216]\n",
    "COLOR_PALETTE[-1] = [255, 255, 225]\n",
    "plt.imshow(COLOR_PALETTE[test_labels.squeeze(0).detach().cpu()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fjNU-Z7Ux9C4"
   },
   "outputs": [],
   "source": [
    "plt.imshow(COLOR_PALETTE[test[1].squeeze(0).detach().cpu()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO0VgN+X1owXwMT2f79YVay",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.9.13 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3be4b77e060bb22088c6a6c3e8b71888dd32b8154f07cd7072936554e65c441a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
